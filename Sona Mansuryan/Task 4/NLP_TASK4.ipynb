{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **BBC News Classification with Custom BoW & TF-IDF**"
   ],
   "metadata": {
    "id": "KA3SV9HbMHuN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Load BBC Dataset**"
   ],
   "metadata": {
    "id": "zZHml4H9MJzX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "df = pd.read_csv(\"bbc-text.csv\", encoding = \"latin1\")\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "id": "Q1TIsGjqah8O",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "outputId": "e5adaffe-285f-458f-a31f-c949318f920b"
   },
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-d0f64a74-ba0a-4396-b875-c5a28ed20197\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-d0f64a74-ba0a-4396-b875-c5a28ed20197\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving bbc-text.csv to bbc-text (2).csv\n",
      "        category                                               text\n",
      "0           tech  tv future in the hands of viewers with home th...\n",
      "1       business  worldcom boss  left books alone  former worldc...\n",
      "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
      "3          sport  yeading face newcastle in fa cup premiership s...\n",
      "4  entertainment  ocean s twelve raids box office ocean s twelve...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Data Preprocessing**\n",
    "\n",
    "\n",
    "*   Clean text\n",
    "*   Tokenize text\n",
    "\n"
   ],
   "metadata": {
    "id": "yny57d6sMbVH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "  text = text.lower()\n",
    "  text = re.sub(r\"\\d+\", \" \", text)\n",
    "  tokens = text.split()\n",
    "  tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "  return tokens\n",
    "\n",
    "df['tokens'] = df['text'].apply(preprocess)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AM_tCAExMbma",
    "outputId": "658d7fdd-822d-4240-9b66-8b22eeffc7dc"
   },
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "lLSjWYebNZ4X",
    "outputId": "d341c7ff-9ed0-4aa9-b004-21683fc8dddd"
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           category                                               text  \\\n",
       "0              tech  tv future in the hands of viewers with home th...   \n",
       "1          business  worldcom boss  left books alone  former worldc...   \n",
       "2             sport  tigers wary of farrell  gamble  leicester say ...   \n",
       "3             sport  yeading face newcastle in fa cup premiership s...   \n",
       "4     entertainment  ocean s twelve raids box office ocean s twelve...   \n",
       "...             ...                                                ...   \n",
       "2220       business  cars pull down us retail figures us retail sal...   \n",
       "2221       politics  kilroy unveils immigration policy ex-chatshow ...   \n",
       "2222  entertainment  rem announce new glasgow concert us band rem h...   \n",
       "2223       politics  how political squabbles snowball it s become c...   \n",
       "2224          sport  souness delight at euro progress boss graeme s...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [tv, future, hands, viewers, home, theatre, sy...  \n",
       "1     [worldcom, boss, left, books, alone, former, w...  \n",
       "2     [tigers, wary, farrell, gamble, leicester, say...  \n",
       "3     [yeading, face, newcastle, fa, cup, premiershi...  \n",
       "4     [ocean, twelve, raids, box, office, ocean, twe...  \n",
       "...                                                 ...  \n",
       "2220  [cars, pull, us, retail, figures, us, retail, ...  \n",
       "2221  [kilroy, unveils, immigration, policy, exchats...  \n",
       "2222  [rem, announce, new, glasgow, concert, us, ban...  \n",
       "2223  [political, squabbles, snowball, become, commo...  \n",
       "2224  [souness, delight, euro, progress, boss, graem...  \n",
       "\n",
       "[2225 rows x 3 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-5a9e1879-b20d-4a06-ad3b-a0685148b1bf\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>[tv, future, hands, viewers, home, theatre, sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>[worldcom, boss, left, books, alone, former, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>[tigers, wary, farrell, gamble, leicester, say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>[yeading, face, newcastle, fa, cup, premiershi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>[ocean, twelve, raids, box, office, ocean, twe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>business</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "      <td>[cars, pull, us, retail, figures, us, retail, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>politics</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "      <td>[kilroy, unveils, immigration, policy, exchats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "      <td>[rem, announce, new, glasgow, concert, us, ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>politics</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "      <td>[political, squabbles, snowball, become, commo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>sport</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "      <td>[souness, delight, euro, progress, boss, graem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 3 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a9e1879-b20d-4a06-ad3b-a0685148b1bf')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5a9e1879-b20d-4a06-ad3b-a0685148b1bf button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5a9e1879-b20d-4a06-ad3b-a0685148b1bf');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-e87c7288-d3fd-4bd1-a08e-cc330141ac9f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e87c7288-d3fd-4bd1-a08e-cc330141ac9f')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-e87c7288-d3fd-4bd1-a08e-cc330141ac9f button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_ac353063-0eb4-47e4-8890-0127e5eb9075\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_ac353063-0eb4-47e4-8890-0127e5eb9075 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df",
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2225,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"business\",\n          \"politics\",\n          \"sport\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2126,\n        \"samples\": [\n          \"plan to give elderly care control elderly and disabled people would choose how their own budget for personal care was spent and organised under government plans.  ministers say elderly and disabled people themselves  not social workers  should be able to decide on their care and stay in their own homes. they also plan a supremo for adult services in each english area to get different agencies working together. but the government shunned opponents  calls for free long-term care.  there are 1.7m people needing care in england and ministers suggest the number could quadruple by 2050. monday s consultation paper on social care for adults in england is aimed at ending a system which generates dependency. health minister stephen ladyman said:  this document is the antithesis of the nanny state.   it s about taking power away from the state and giving it to individuals and saying that we will help you make these decisions but we are not going to make them for you any more.  the government has already allowed local councils to give people money so they can pay for their services directly but take-up of the scheme has been  disappointing .  ministers say the new plans would make direct payments simpler and try to counter reluctance in some local councils to use the payments. they also want to set up a new  half-way house  where social workers tell people how much money is available for their care and help them choose how to spend that  individual budget . the scheme will be funded on existing budgets set until 2008. but mr ladyman said the plans could deliver savings in some areas  such as freeing up nhs beds and preventing illnesses. he ruled out free personal care in england - which is on offer in scotland and wales  saying it was  unsustainable .  david rogers  from the local government association  said agencies were working together on the kind of innovation proposed by the government. and tony hunter  president of the association of directors of social services  said the plans could improve dignity and well-being for thousands of people. but age concern argued social care was chronically under-funded and older people were being offered choice in principle  but not in practice. its director general  gordon lishman  said:  direct payments will not work if there are no services for people to choose from locally.   the tories say people who pay for three years  long-term care directly or through insurance should be guaranteed free care for the rest of their lives. tory spokesman simon burns said more than 80 000 long term care places had been lost since 1997.  after eight years of persistent change  dogmatic enforcement of regulation  and overbearing government initiatives - we need action  not a vision   said mr burns. the lib dems say they would fund free personal care by a new 50% tax rate on incomes over \\u00c2\\u00a3100 000. health spokesman paul burstow said:  promoting independence sounds good and helping people to live in their own homes is a goal we share.  but the risk is that independence can turn into isolation if the right support and care is not available.\",\n          \"beer giant swallows russian firm brewing giant inbev has agreed to buy alfa-eco s stake in sun interbrew  russia s second-largest brewer  for up to 259.7m euros ($353.3m; \\u00c2\\u00a3183.75m).  alfa-eco  the venture capital arm of russian conglomerate alfa group  has a one-fifth stake in sun interbrew. the deal gives inbev  the world s biggest beermaker  near-total control over the russian brewer. inbev bought out another partner in august 2004. inbev brands include bass  stella artois  hoegaarden and staropramen. it employs 77 000 people  running operations in over 30 countries across the americas  europe and asia pacific.  the leuven-based brewery said it would own 97.3% of the voting shares and 98.8% of the non-voting shares of sun interbrew. the deal is expected to be completed in the first quarter of 2005. inbev was formed in august 2004 when belgium s interbrew bought brazilian brewer ambev. sun interbrew  which employs 8 000 staff  owns breweries in eight russian cities - klin  ivanovo  saransk  kursk  volzhsky  omsk  perm and novocheboksarsk. there are also three breweries in ukraine  in the cities of chernigov  nikolaev and kharkov.\",\n          \"athens memories soar above lows well  it s goodbye to another olympic year and as usual there were plenty of highs and lows in athens.  obviously  there s no getting away from the differing fortunes of kelly holmes and paula radcliffe. but i want to remind you of a few more events that made 2004 another year to remember - or forget - for athletics.      one of my favourite olympic moments was kelly s success in the 800m.  winning that race was the key to her success because if she won that then the 1500m would be a bit of a formality. kelly had been full of  should i  shouldn t i   thoughts about going for the double in athens. i thought why wouldn t you do the 800m  it s your best event  it was such good fun to commentate on her 1500m and it was nice to be able to be part of her athens story.      the victory for the british men s 4x100m relay team was a bit of a surprise but a great climax to the games. i think the four of them - jason gardener  darren campbell  marlon devonish and mark lewis-francis - knew deep down that it was their best chance of a medal. the lads had run poorly in the individual sprints so maybe they did lift their game when they knew something was really at stake.      hicham el guerrouj s olympic double is a much bigger achievement than kelly s on a global scale.  he was the first man since for 80 years to win both the 1500m and 5 000m titles. as soon as he had added the 5 000m crown and i had finished commentating  i jumped up  ran down the stairs  pushed everyone out the way and just gave him a big hug. he is one of the few african runners who has embraced the tradition of the mile and he loves to hear all the roger bannister stories. hicham is someone i enjoy having a bit of time with  even though my french and his english are not very good.      what happened to paula in athens this year is the obvious low on a personal level and for the expectations of the nation as well. there were a set of circumstances around athens that conspired to produce a very dramatic ending which i think has been greatly misunderstood. dropping out of the marathon was the right thing to do but starting in the 10 000m five days later was not wise. that was her heart and not her head reacting. paula had a lot of little things going wrong in her preparation and on the day.  things like niggling injuries  not being able to do all her running sessions and feeling the pressure of the race looming ahead of her. i think she came to the start line in athens physically and emotionally drained. and if even the smallest thing doesn t feel right when you are preparing to race a marathon  10 miles down the road it will hit you like a brick wall. the positive thing to take from paula s olympics it that she will have learned a lot from it and so will a lot of people - including me.      purely as a race  paula s victory in the new york marathon has to go down as one of the most thrilling. it was so nip-and-tuck between her and kenya s susan chepkemei and you don t usually get that kind of excitement in marathons. it was also a real delight for all athletics fans because  to use one of my favourite words  paula showed real  bouncebackability . and it was a bit of a rarity for me too because i genuinely did not have an inkling how the race was going to pan out.      kelly and the 4x100m boys  victories papered over the cracks in the general performance of the british team. we should be concerned that we re not producing enough people who are capable of reaching finals at senior level.  the only individual men s finalist on the track was michael east in the 1500m. i am beginning to look down and wonder where are the new breed  and that s where things begin to look even gloomier for british athletics as we did not win any medals at the world junior championships in italy. dani barnes came fourth in the 1500m and she was the highest finisher for team gb. the thing is if we don t have athletes getting into the finals at junior level then it really doesn t look good for the beijing olympics and beyond.      i tell you what i really enjoyed this year  benita johnson winning the world cross country championships back in march. in the absence of paula  we tend to think of the event as something of an african preserve. so to have an australian come up and deliver such a surprise was something special.      to be honest  i m getting bored with all the drug scandals  especially balco. i just wish the whole thing would come to a head so we can move on.  having said that  i m always pleased when drugs cheats are caught because it shows the sport is standing up to it and not turning a blind eye anymore. and one of the positive things to come out of balco is people are starting to blow the whistle. we need more people to come forward and help the authorities kick out the cheats. as regards the case against greek sprinters kostas kenteris and katerina thanou  well suspicions have been hanging over kenteris for a while. the bottom line is we cannot keep letting drugs damage the sport because if we do then it stops everyone enjoying it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 48
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Bag of Words (BoW)**\n",
    "\n",
    "*   Build vocabulary from all documents\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "QTs-P7KlScYb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "all_tokens = set()\n",
    "for tokens in df['tokens']:\n",
    "    all_tokens.update(tokens)\n",
    "\n",
    "sorted_tokens = sorted(all_tokens)\n",
    "\n",
    "vocabulary = {word: idx for idx, word in enumerate(sorted_tokens)}\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "print(\"First 20 words:\", list(vocabulary.items())[:20])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EQyi6_5Z6p7",
    "outputId": "9104af22-5064-4357-c6e1-110d69f4be5b"
   },
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vocabulary size: 30171\n",
      "First 20 words: [('aa', 0), ('aaa', 1), ('aaas', 2), ('aac', 3), ('aadc', 4), ('aaliyah', 5), ('aaltra', 6), ('aamir', 7), ('aan', 8), ('aara', 9), ('aarhus', 10), ('aaron', 11), ('abacus', 12), ('abandon', 13), ('abandoned', 14), ('abandoning', 15), ('abandonment', 16), ('abate', 17), ('abatement', 18), ('abating', 19)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "*   Convert a document to BoW vector\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "pi3AkW8IOX8y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "bag_of_words = []\n",
    "for tokens in df['tokens']:\n",
    "    vector = [0] * len(vocabulary)\n",
    "    for token in tokens:\n",
    "        if token in vocabulary:\n",
    "            vector[vocabulary[token]] += 1\n",
    "    bag_of_words.append(vector)\n",
    "\n",
    "bag_of_words = np.array(bag_of_words)\n",
    "\n",
    "df['bow_vector'] = list(bag_of_words)\n",
    "\n",
    "index_to_word_bow = {index: word for word, index in vocabulary.items()}\n",
    "\n",
    "first_bow = bag_of_words[0]\n",
    "\n",
    "first_20_bow = [(index_to_word_bow[i], round(first_bow[i], 4)) for i in range(20)]\n",
    "\n",
    "print(\"First 20 words and their counts (first document):\")\n",
    "for word, count in first_20_bow:\n",
    "    print(f\"  {word}: {count}\")"
   ],
   "metadata": {
    "id": "ILCACUwnOZXb",
    "outputId": "9610ff46-42e3-429d-9ce9-3d8f7e5122a0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First 20 words and their counts (first document):\n",
      "  aa: 0\n",
      "  aaa: 0\n",
      "  aaas: 0\n",
      "  aac: 0\n",
      "  aadc: 0\n",
      "  aaliyah: 0\n",
      "  aaltra: 0\n",
      "  aamir: 0\n",
      "  aan: 0\n",
      "  aara: 0\n",
      "  aarhus: 0\n",
      "  aaron: 0\n",
      "  abacus: 0\n",
      "  abandon: 0\n",
      "  abandoned: 0\n",
      "  abandoning: 0\n",
      "  abandonment: 0\n",
      "  abate: 0\n",
      "  abatement: 0\n",
      "  abating: 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4. TF-IDF Implementation**\n",
    "\n",
    "\n",
    "*   Compute Term Frequency (TF)\n",
    "\n"
   ],
   "metadata": {
    "id": "qey65qj3rDKF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_tf(tokens, vocabulary):\n",
    "    tf_vector = np.zeros(len(vocabulary))\n",
    "    total_words = len(tokens)\n",
    "\n",
    "    for word in tokens:\n",
    "        if word in vocabulary:\n",
    "            tf_vector[vocabulary[word]] += 1\n",
    "\n",
    "    return tf_vector / total_words\n",
    "\n",
    "df['tf_vector'] = df['tokens'].apply(lambda x: compute_tf(x, vocabulary))\n",
    "\n",
    "index_to_word = {idx: word for word, idx in vocabulary.items()}\n",
    "\n",
    "first_tf = df['tf_vector'].iloc[0]\n",
    "first_20_tf = [(index_to_word[i], round(first_tf[i], 4)) for i in range(20)]\n",
    "print(\"First 20 words and their TF values (first document)\")\n",
    "for word, score in first_20_tf:\n",
    "    print(f\"  {word}: {score:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUx8gKoCrQCR",
    "outputId": "1c08627d-065a-4359-9777-5e03a18247b9"
   },
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First 20 words and their TF values (first document)\n",
      "  aa: 0.0000\n",
      "  aaa: 0.0000\n",
      "  aaas: 0.0000\n",
      "  aac: 0.0000\n",
      "  aadc: 0.0000\n",
      "  aaliyah: 0.0000\n",
      "  aaltra: 0.0000\n",
      "  aamir: 0.0000\n",
      "  aan: 0.0000\n",
      "  aara: 0.0000\n",
      "  aarhus: 0.0000\n",
      "  aaron: 0.0000\n",
      "  abacus: 0.0000\n",
      "  abandon: 0.0000\n",
      "  abandoned: 0.0000\n",
      "  abandoning: 0.0000\n",
      "  abandonment: 0.0000\n",
      "  abate: 0.0000\n",
      "  abatement: 0.0000\n",
      "  abating: 0.0000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "*   Compute Inverse Document Frequency (IDF)\n"
   ],
   "metadata": {
    "id": "OrCUoXTIasZF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "def compute_idf(all_data, vocabulary):\n",
    "    N = len(all_data)\n",
    "    idf_vector = []\n",
    "    for word in vocabulary:\n",
    "        df_count = sum(1 for doc in all_data if word in doc)\n",
    "        idf = math.log((N + 1) / (df_count + 1)) + 1\n",
    "        idf_vector.append(idf)\n",
    "    return np.array(idf_vector)\n",
    "\n",
    "idf_vector = compute_idf(df['tokens'], vocabulary)\n",
    "\n",
    "first_20_idf = [(index_to_word[i], round(idf_vector[i], 4)) for i in range(20)]\n",
    "print(\"\\nFirst 20 words and their IDF values\")\n",
    "for word, score in first_20_idf:\n",
    "    print(f\"  {word}: {score:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSKXKunWPIFE",
    "outputId": "d0784148-4ce3-4ce2-c882-8ae2b275ab60"
   },
   "execution_count": 64,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "First 20 words and their IDF values\n",
      "  aa: 8.0148\n",
      "  aaa: 6.5107\n",
      "  aaas: 6.6285\n",
      "  aac: 7.6093\n",
      "  aadc: 8.0148\n",
      "  aaliyah: 8.0148\n",
      "  aaltra: 8.0148\n",
      "  aamir: 8.0148\n",
      "  aan: 8.0148\n",
      "  aara: 8.0148\n",
      "  aarhus: 8.0148\n",
      "  aaron: 6.9162\n",
      "  abacus: 7.6093\n",
      "  abandon: 7.3217\n",
      "  abandoned: 5.8176\n",
      "  abandoning: 6.6285\n",
      "  abandonment: 6.9162\n",
      "  abate: 8.0148\n",
      "  abatement: 8.0148\n",
      "  abating: 7.6093\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "*   Compute TF-IDF vectors for each document\n"
   ],
   "metadata": {
    "id": "78l6-VKgajiG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_tfidf(tf_vector, idf_vector):\n",
    "    return tf_vector * idf_vector\n",
    "\n",
    "df['tfidf_vector'] = df['tf_vector'].apply(lambda x: compute_tfidf(x, idf_vector))\n",
    "\n",
    "first_tfidf = df['tfidf_vector'].iloc[0]\n",
    "first_tfidf = df['tfidf_vector'].iloc[0]\n",
    "\n",
    "top_indices = np.argsort(first_tfidf)[-20:][::-1]\n",
    "top_words = [index_to_word[i] for i in top_indices]\n",
    "top_scores = [first_tfidf[i] for i in top_indices]\n",
    "\n",
    "print(\"Top 20 TF-IDF words in first document:\")\n",
    "for w, s in zip(top_words, top_scores):\n",
    "    print(f\"  {w}: {s:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wVIUiB7ahSA",
    "outputId": "47014b2a-fcce-41c4-81fa-6fc9f8cf0487"
   },
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 20 TF-IDF words in first document:\n",
      "  tv: 0.0999\n",
      "  dvr: 0.0748\n",
      "  hanlon: 0.0591\n",
      "  highdefinition: 0.0525\n",
      "  tivo: 0.0489\n",
      "  want: 0.0472\n",
      "  watch: 0.0434\n",
      "  satellite: 0.0425\n",
      "  content: 0.0404\n",
      "  brands: 0.0382\n",
      "  brand: 0.0378\n",
      "  programmes: 0.0352\n",
      "  people: 0.0348\n",
      "  viewers: 0.0346\n",
      "  us: 0.0341\n",
      "  schedules: 0.0340\n",
      "  means: 0.0339\n",
      "  channel: 0.0338\n",
      "  technologies: 0.0332\n",
      "  lcd: 0.0326\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**5. Analysis**"
   ],
   "metadata": {
    "id": "LE9MSL87rtNt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*   Top-10 words by average TF-IDF\n",
    "\n"
   ],
   "metadata": {
    "id": "MdPAofG6sceE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "categories = df['category'].unique()\n",
    "\n",
    "index_to_word = {idx: word for word, idx in vocabulary.items()}\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"\\nTop TF-IDF Words for category: {category}\")\n",
    "\n",
    "    cat_df = df[df['category'] == category]\n",
    "\n",
    "    tfidf_matrix = np.stack(cat_df['tfidf_vector'].values)\n",
    "\n",
    "    avg_tfidf = tfidf_matrix.mean(axis=0)\n",
    "\n",
    "    sorted_indices = np.argsort(avg_tfidf)[::-1]\n",
    "\n",
    "    for i in sorted_indices[:10]:\n",
    "        word = index_to_word[i]\n",
    "        score = avg_tfidf[i]\n",
    "        print(f\"  {word}: {score:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ssh8WnHLrzUc",
    "outputId": "8b081336-2dab-470e-c5b3-51763c75e178"
   },
   "execution_count": 66,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Top TF-IDF Words for category: tech\n",
      "  people: 0.0174\n",
      "  said: 0.0169\n",
      "  users: 0.0149\n",
      "  software: 0.0147\n",
      "  mobile: 0.0145\n",
      "  technology: 0.0133\n",
      "  microsoft: 0.0121\n",
      "  net: 0.0114\n",
      "  digital: 0.0112\n",
      "  computer: 0.0111\n",
      "\n",
      "Top TF-IDF Words for category: business\n",
      "  bn: 0.0243\n",
      "  said: 0.0206\n",
      "  us: 0.0164\n",
      "  growth: 0.0136\n",
      "  bank: 0.0134\n",
      "  company: 0.0130\n",
      "  economy: 0.0125\n",
      "  year: 0.0125\n",
      "  market: 0.0125\n",
      "  sales: 0.0123\n",
      "\n",
      "Top TF-IDF Words for category: sport\n",
      "  england: 0.0147\n",
      "  game: 0.0146\n",
      "  said: 0.0139\n",
      "  win: 0.0134\n",
      "  cup: 0.0124\n",
      "  match: 0.0115\n",
      "  club: 0.0109\n",
      "  injury: 0.0107\n",
      "  chelsea: 0.0104\n",
      "  play: 0.0102\n",
      "\n",
      "Top TF-IDF Words for category: entertainment\n",
      "  film: 0.0353\n",
      "  best: 0.0193\n",
      "  show: 0.0150\n",
      "  music: 0.0143\n",
      "  said: 0.0140\n",
      "  awards: 0.0137\n",
      "  band: 0.0128\n",
      "  award: 0.0123\n",
      "  festival: 0.0117\n",
      "  album: 0.0116\n",
      "\n",
      "Top TF-IDF Words for category: politics\n",
      "  mr: 0.0326\n",
      "  said: 0.0259\n",
      "  labour: 0.0239\n",
      "  blair: 0.0196\n",
      "  election: 0.0193\n",
      "  party: 0.0193\n",
      "  government: 0.0172\n",
      "  would: 0.0167\n",
      "  brown: 0.0131\n",
      "  minister: 0.0125\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "*   high TF/low IDF & low TF/high IDF\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "bWDmpZ55cfNn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_bow = np.stack(df['bow_vector'].values)\n",
    "global_tf = np.sum(X_bow, axis=0) / np.sum(X_bow)\n",
    "\n",
    "index_to_word = {idx: word for word, idx in vocabulary.items()}\n",
    "\n",
    "tf_idf_df = pd.DataFrame({\n",
    "    'word': [index_to_word[i] for i in range(len(vocabulary))],\n",
    "    'global_tf': global_tf,\n",
    "    'idf': idf_vector\n",
    "})\n",
    "\n",
    "high_tf_low_idf = tf_idf_df.sort_values(['global_tf', 'idf'], ascending=[False, True]).head(10)\n",
    "low_tf_high_idf = tf_idf_df.sort_values(['global_tf', 'idf'], ascending=[True, False]).head(10)\n",
    "\n",
    "print(\"High TF & Low IDF words:\")\n",
    "for _, row in high_tf_low_idf.iterrows():\n",
    "    print(f\"  {row['word']}: TF={row['global_tf']:.4f}, IDF={row['idf']:.4f}\")\n",
    "\n",
    "print(\"\\nLow TF & High IDF words:\")\n",
    "for _, row in low_tf_high_idf.iterrows():\n",
    "    print(f\"  {row['word']}: TF={row['global_tf']:.4f}, IDF={row['idf']:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sGL4uXu7cq7m",
    "outputId": "9064b233-791d-4463-845a-695cd2e834d0"
   },
   "execution_count": 67,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "High TF & Low IDF words:\n",
      "  said: TF=0.0151, IDF=1.1642\n",
      "  mr: TF=0.0062, IDF=2.0347\n",
      "  would: TF=0.0054, IDF=1.6631\n",
      "  also: TF=0.0045, IDF=1.5643\n",
      "  people: TF=0.0043, IDF=2.0259\n",
      "  new: TF=0.0041, IDF=1.8214\n",
      "  us: TF=0.0040, IDF=1.9805\n",
      "  year: TF=0.0039, IDF=1.7992\n",
      "  one: TF=0.0037, IDF=1.7736\n",
      "  could: TF=0.0031, IDF=1.9326\n",
      "\n",
      "Low TF & High IDF words:\n",
      "  aa: TF=0.0000, IDF=8.0148\n",
      "  aaltra: TF=0.0000, IDF=8.0148\n",
      "  aamir: TF=0.0000, IDF=8.0148\n",
      "  aan: TF=0.0000, IDF=8.0148\n",
      "  aara: TF=0.0000, IDF=8.0148\n",
      "  aarhus: TF=0.0000, IDF=8.0148\n",
      "  abate: TF=0.0000, IDF=8.0148\n",
      "  abatement: TF=0.0000, IDF=8.0148\n",
      "  abbot: TF=0.0000, IDF=8.0148\n",
      "  abbreviated: TF=0.0000, IDF=8.0148\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**6. Save cleaned CSV**"
   ],
   "metadata": {
    "id": "6cOAJkEC3cx5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "output_df = df[['category', 'text', 'tokens']].copy()\n",
    "\n",
    "high_tf_low_words = [w for w in high_tf_low_idf['word']]\n",
    "low_tf_high_words = [w for w in low_tf_high_idf['word']]\n",
    "\n",
    "output_df['High TF/Low IDF'] = \", \".join(high_tf_low_words)\n",
    "output_df['Low TF/High IDF'] = \", \".join(low_tf_high_words)\n",
    "\n",
    "output_df.to_csv(\"cleaned_bbc_text.csv\", index=False, encoding='utf-8')"
   ],
   "metadata": {
    "id": "L7y4ufOY8B2f"
   },
   "execution_count": 68,
   "outputs": []
  }
 ]
}
