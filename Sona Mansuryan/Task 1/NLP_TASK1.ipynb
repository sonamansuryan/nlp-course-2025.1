{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Preprocessing with Basic Python**"
      ],
      "metadata": {
        "id": "q0b9roOXmyuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Input text and Tokenization**"
      ],
      "metadata": {
        "id": "WO1j0H21nAQZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c61nkZD3FL1o",
        "outputId": "6a244afb-d4e0-4229-8f3d-a307f4edfa54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 - Tokenization ['Natural', 'Language', 'Processing', '(NLP)', 'is', 'a', 'subfield', 'of', 'linguistics,', 'computer', 'science,', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language.', \"It's\", 'used', 'to', 'analyze', 'text,', 'allowing', 'machines', 'to', 'understand,', 'interpret,', 'and', 'manipulate', 'human', 'language.', 'NLP', 'has', 'many', 'real-world', 'applications,', 'including', 'machine', 'translation,', 'sentiment', 'analysis,', 'and', 'chatbots.']\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"Natural Language Processing (NLP) is a subfield of linguistics, computer science, and\n",
        "artificial intelligence concerned with the interactions between computers and human language.\n",
        "It's used to analyze text, allowing machines to understand, interpret, and manipulate human language.\n",
        "NLP has many real-world applications, including machine translation, sentiment analysis, and chatbots.\"\"\"\n",
        "\n",
        "text_token = text.split()\n",
        "print(\"Step 1 - Tokenization\", text_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Lowercasing**"
      ],
      "metadata": {
        "id": "g7ilQ0h-nEHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_lower = [i.lower() for i in text_token]\n",
        "print(\"Step 2 - Lowercasing\", token_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eehcoWaxGCfn",
        "outputId": "ded22b85-34bd-4ca2-ddf8-cf3527912ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2 - Lowercasing ['natural', 'language', 'processing', '(nlp)', 'is', 'a', 'subfield', 'of', 'linguistics,', 'computer', 'science,', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language.', \"it's\", 'used', 'to', 'analyze', 'text,', 'allowing', 'machines', 'to', 'understand,', 'interpret,', 'and', 'manipulate', 'human', 'language.', 'nlp', 'has', 'many', 'real-world', 'applications,', 'including', 'machine', 'translation,', 'sentiment', 'analysis,', 'and', 'chatbots.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Punctuation Removal**"
      ],
      "metadata": {
        "id": "J-tlkrT-nJ-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "token_no_punct = [token.translate(str.maketrans('', '', string.punctuation)) for token in token_lower]\n",
        "print(\"Step 3 - Punctuation removal:\", token_no_punct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghuM9NSXHxQG",
        "outputId": "4bc14bc5-80b5-42a0-a9ab-ebcfafb42140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3 - Punctuation removal: ['natural', 'language', 'processing', 'nlp', 'is', 'a', 'subfield', 'of', 'linguistics', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', 'its', 'used', 'to', 'analyze', 'text', 'allowing', 'machines', 'to', 'understand', 'interpret', 'and', 'manipulate', 'human', 'language', 'nlp', 'has', 'many', 'realworld', 'applications', 'including', 'machine', 'translation', 'sentiment', 'analysis', 'and', 'chatbots']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Stop Word Removal**"
      ],
      "metadata": {
        "id": "IQIb4r7MnPCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = [\"the\", \"a\", \"an\", \"in\", \"on\", \"at\", \"for\", \"to\", \"of\", \"and\", \"is\", \"are\"]\n",
        "\n",
        "token_no_stopwords = [token for token in token_no_punct if token not in stop_words]\n",
        "\n",
        "print(\"Step 4 - Stop Word Removal:\", token_no_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InmrJtp7IO6E",
        "outputId": "8da8b434-1f14-4054-9dd3-0ab1c36d9ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 4 - Stop Word Removal: ['natural', 'language', 'processing', 'nlp', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'with', 'interactions', 'between', 'computers', 'human', 'language', 'its', 'used', 'analyze', 'text', 'allowing', 'machines', 'understand', 'interpret', 'manipulate', 'human', 'language', 'nlp', 'has', 'many', 'realworld', 'applications', 'including', 'machine', 'translation', 'sentiment', 'analysis', 'chatbots']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Stemming**"
      ],
      "metadata": {
        "id": "qSSB5uh7nYc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_stem(token):\n",
        "    for suffix in ['ing', 'ed', 's']:\n",
        "        if token.endswith(suffix):\n",
        "            return token[:-len(suffix)]\n",
        "    return token\n",
        "\n",
        "stemmed_tokens = [simple_stem(token) for token in token_no_stopwords]\n",
        "\n",
        "print(\"Step 5 - Stemming\", stemmed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5MMoxV4MgBf",
        "outputId": "59fec3d1-4f9d-47a5-fa7f-d0c3b798ccfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 5 - Stemming ['natural', 'language', 'process', 'nlp', 'subfield', 'linguistic', 'computer', 'science', 'artificial', 'intelligence', 'concern', 'with', 'interaction', 'between', 'computer', 'human', 'language', 'it', 'us', 'analyze', 'text', 'allow', 'machine', 'understand', 'interpret', 'manipulate', 'human', 'language', 'nlp', 'ha', 'many', 'realworld', 'application', 'includ', 'machine', 'translation', 'sentiment', 'analysi', 'chatbot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Bonus Step: Lemmatization**"
      ],
      "metadata": {
        "id": "Ii9WgVLZnaSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemma_dict = {\n",
        "     \"is\": \"be\",\n",
        "    \"are\": \"be\",\n",
        "    \"was\": \"be\",\n",
        "    \"were\": \"be\",\n",
        "    \"has\": \"have\",\n",
        "    \"had\": \"have\",\n",
        "    \"does\": \"do\",\n",
        "    \"did\": \"do\",\n",
        "    \"machines\": \"machine\",\n",
        "    \"computers\": \"computer\",\n",
        "    \"interactions\": \"interaction\",\n",
        "    \"languages\": \"language\",\n",
        "    \"used\": \"use\",\n",
        "    \"allowing\": \"allow\",\n",
        "    \"applications\": \"application\",\n",
        "    \"including\": \"include\",\n",
        "}\n",
        "\n",
        "lemmatized_tokens = [lemma_dict.get(token, token) for token in stemmed_tokens]\n",
        "\n",
        "print(\"Bonus Step - Lemmatized Tokens:\", lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6bSRC5fcwAT",
        "outputId": "f9e23353-e81c-44d2-b266-f639c3fc55c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonus Step - Lemmatized Tokens: ['natural', 'language', 'process', 'nlp', 'subfield', 'linguistic', 'computer', 'science', 'artificial', 'intelligence', 'concern', 'with', 'interaction', 'between', 'computer', 'human', 'language', 'it', 'us', 'analyze', 'text', 'allow', 'machine', 'understand', 'interpret', 'manipulate', 'human', 'language', 'nlp', 'ha', 'many', 'realworld', 'application', 'includ', 'machine', 'translation', 'sentiment', 'analysi', 'chatbot']\n"
          ]
        }
      ]
    }
  ]
}